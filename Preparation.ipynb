{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SSU_4ezt6_GRNNWNtLeHNdnPAp-vunVQ",
      "authorship_tag": "ABX9TyN5JPqlV4UYVDqPJNr0M7va",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjana-joshi14/Ecommerce-Analysis/blob/main/Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DLUMhK7PDEJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_df = pd.read_csv('/content/olist_customers_dataset.csv')\n",
        "products_df = pd.read_csv('/content/olist_products_dataset.csv')\n",
        "orders_df = pd.read_csv('/content/olist_orders_dataset.csv')\n",
        "items_df = pd.read_csv('/content/olist_order_items_dataset.csv')\n",
        "cat_names_df = pd.read_csv('/content/product_category_name_translation.csv')\n",
        "payments_df = pd.read_csv('/content/olist_order_payments_dataset.csv')\n",
        "geos_df = pd.read_csv('/content/olist_geolocation_dataset.csv')\n",
        "sellers_df = pd.read_csv('/content/olist_sellers_dataset.csv')"
      ],
      "metadata": {
        "id": "Tnr8YrXpayV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging files to common IDs\n",
        "full_df = orders_df.merge(payments_df, on='order_id')\\\n",
        ".merge(items_df, on='order_id')\\\n",
        ".merge(customer_df, on='customer_id')\\\n",
        ".merge(products_df, on='product_id')"
      ],
      "metadata": {
        "id": "RwXVwP0mgCpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUnction to summarize columns in the dataset\n",
        "def df_summary(df):\n",
        "  summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n",
        "  summary = summary.reset_index()\n",
        "  summary['Column'] = summary['index']\n",
        "  summary = summary[['Column','dtypes']]\n",
        "  summary['# unique'] = df.nunique().values\n",
        "  summary['# duplicates'] = df.duplicated().sum()\n",
        "  summary['# missing'] = df.isnull().sum().values\n",
        "  summary['Example'] = df.loc[0].values\n",
        "\n",
        "  return summary\n",
        "\n",
        "  df_summary(full_df)"
      ],
      "metadata": {
        "id": "1unLn0D2dIj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save merged df as CSV\n",
        "full_df.to_csv('Mergev2.csv', index=False)"
      ],
      "metadata": {
        "id": "P_XuKz68vo5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing main DB as MERGED\n",
        "\n",
        "# Import necessary libraries\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account # Import for explicit authentication\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "# Explicitly provide credentials using a service account key file\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    '/content/drive/MyDrive/x.json'  # Replace with the actual path\n",
        ")\n",
        "client = bigquery.Client(credentials=credentials)\n",
        "\n",
        "\n",
        "# Define your BigQuery dataset and table.\n",
        "project_id = \"p1-ecomm\"\n",
        "dataset_id = \"T1_ECOMM\"  # Replace with your dataset ID\n",
        "table_id = \"MERGED\"     # Replace with your table ID\n",
        "table_ref = client.dataset(dataset_id, project=project_id).table(table_id)\n",
        "\n",
        "\n",
        "# Convert the pandas DataFrame to a BigQuery table.\n",
        "# Replace 'full_df' with the actual variable name containing your dataframe\n",
        "job_config = bigquery.LoadJobConfig()\n",
        "job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE #replace with WRITE_APPEND if you want to add data\n",
        "job = client.load_table_from_dataframe(\n",
        "    full_df, table_ref, job_config=job_config\n",
        ")\n",
        "job.result()  # Wait for the job to complete.\n",
        "\n",
        "print(f\"Loaded {full_df.shape[0]} rows into BigQuery table {table_id}\")"
      ],
      "metadata": {
        "id": "DzciyW3rdGB4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}